{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Deterministic Inputs, Noisy “And” gate model (DINA)\n",
    "\n",
    "This notebook will show you how to train and use the GDDINA.\n",
    "First, we will show how to get the data (here we use a0910 as the dataset).\n",
    "Then we will show how to train a DINA and perform the parameters persistence.\n",
    "At last, we will show how to load the parameters from the file and evaluate on the test dataset.\n",
    "\n",
    "The script version could be found in [DINA.py](DINA.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preparation\n",
    "\n",
    "Before we process the data, we need to first acquire the dataset which is shown in [prepare_dataset.ipynb](prepare_dataset.ipynb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "data": {
      "text/plain": "0         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n1         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n2         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n3         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n4         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n                                ...                        \n241066    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n241067    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n241068    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n241069    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n241070    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\nName: knowledge, Length: 241071, dtype: object"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"../../../data/a0910/train.csv\")\n",
    "valid_data = pd.read_csv(\"../../../data/a0910/valid.csv\")\n",
    "test_data = pd.read_csv(\"../../../data/a0910/test.csv\")\n",
    "item_data = pd.read_csv(\"../../../data/a0910/item.csv\")\n",
    "\n",
    "knowledge_num = 123\n",
    "\n",
    "print(type(item_data[\"knowledge_code\"][0]))\n",
    "def code2vector(x):\n",
    "    vector = [0] * knowledge_num\n",
    "    for k in eval(x):\n",
    "        vector[k - 1] = 1\n",
    "    return vector\n",
    "\n",
    "\n",
    "item_data[\"knowledge\"] = item_data[\"knowledge_code\"].apply(code2vector)\n",
    "item_data.drop(columns=[\"knowledge_code\"], inplace=True)\n",
    "\n",
    "train_data = pd.merge(train_data, item_data, on=\"item_id\")\n",
    "valid_data = pd.merge(valid_data, item_data, on=\"item_id\")\n",
    "test_data = pd.merge(test_data, item_data, on=\"item_id\")\n",
    "\n",
    "train_data['knowledge']\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-01-05T15:53:02.709477133Z",
     "start_time": "2024-01-05T15:53:02.566971142Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "(241071, 33131, 71907)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(valid_data), len(test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "(<torch.utils.data.dataloader.DataLoader at 0x20c1fbdc430>,\n <torch.utils.data.dataloader.DataLoader at 0x20c1fbdf040>,\n <torch.utils.data.dataloader.DataLoader at 0x20c1fbdf700>)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform data to torch Dataloader (i.e., batchify)\n",
    "# batch_size is set to 256\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "def transform(x, y, z, k, batch_size, **params):\n",
    "    dataset = TensorDataset(\n",
    "        torch.tensor(x, dtype=torch.int64),\n",
    "        torch.tensor(y, dtype=torch.int64),\n",
    "        torch.tensor(k, dtype=torch.float32),\n",
    "        torch.tensor(z, dtype=torch.float32)\n",
    "    )\n",
    "    return DataLoader(dataset, batch_size=batch_size, **params)\n",
    "\n",
    "\n",
    "train, valid, test = [\n",
    "    transform(data[\"user_id\"], data[\"item_id\"], data[\"score\"], data[\"knowledge\"], batch_size)\n",
    "    for data in [train_data, valid_data, test_data]\n",
    "]\n",
    "train, valid, test\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_create_directory() - handled error when creating a directory at ../Experiments/8-Preprocessing_pipeline: [Errno 2] No such file or directory: '../Experiments/8-Preprocessing_pipeline'\n",
      "_create_directory() - handled error when creating a directory at ../Experiments/8-Preprocessing_pipeline/05-01-2024-11h21: [Errno 2] No such file or directory: '../Experiments/8-Preprocessing_pipeline/05-01-2024-11h21'\n",
      "create logs - handled error when creating a file at ../Experiments/8-Preprocessing_pipeline/05-01-2024-11h21/running.log: [Errno 2] No such file or directory: '../Experiments/8-Preprocessing_pipeline/05-01-2024-11h21/running.log'\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/arthurb/Programmation/EduCDM/examples/DINA/Experiments/8-Preprocessing_pipeline/05-01-2024-11h21/running.log'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 17\u001B[0m\n\u001B[1;32m     14\u001B[0m rel_xp_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../Experiments\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     15\u001B[0m abs_xp_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/home/arthurb/Programmation/portrait/Experiments\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 17\u001B[0m exp \u001B[38;5;241m=\u001B[39m \u001B[43mDatasetProcessor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mxp_folder_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrel_data_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexperiment_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrel_xp_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m exp\u001B[38;5;241m.\u001B[39mprocess_from_file(dataset_name,abs_xp_path \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m xp_folder_name \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprepro_\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m+\u001B[39mdataset_name \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     19\u001B[0m exp\u001B[38;5;241m.\u001B[39msave_dataset(dataset_name,metadata\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, rebus_format\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[0;32m~/Programmation/portrait/Utility/DatasetProcessor.py:135\u001B[0m, in \u001B[0;36mDatasetProcessor.__init__\u001B[0;34m(self, experiment_nb, data_path, experiment_path, logging_level)\u001B[0m\n\u001B[1;32m    130\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m error:\n\u001B[1;32m    131\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlogger\u001B[38;5;241m.\u001B[39mwarning(\n\u001B[1;32m    132\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcreate logs - handled error when creating a file at \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mxp_path \u001B[38;5;241m+\u001B[39m log_name \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(\n\u001B[1;32m    133\u001B[0m             error))\n\u001B[0;32m--> 135\u001B[0m fh \u001B[38;5;241m=\u001B[39m \u001B[43mlogging\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mFileHandler\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mxp_path\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mlog_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    136\u001B[0m fh\u001B[38;5;241m.\u001B[39msetLevel(logging_level)\n\u001B[1;32m    137\u001B[0m formatter \u001B[38;5;241m=\u001B[39m logging\u001B[38;5;241m.\u001B[39mFormatter(\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%(levelname)s\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m%(message)s\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/conda_EduCDM/lib/python3.8/logging/__init__.py:1147\u001B[0m, in \u001B[0;36mFileHandler.__init__\u001B[0;34m(self, filename, mode, encoding, delay)\u001B[0m\n\u001B[1;32m   1145\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstream \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1146\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1147\u001B[0m     StreamHandler\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/anaconda3/envs/conda_EduCDM/lib/python3.8/logging/__init__.py:1176\u001B[0m, in \u001B[0;36mFileHandler._open\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1171\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_open\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m   1172\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1173\u001B[0m \u001B[38;5;124;03m    Open the current base file with the (original) mode and encoding.\u001B[39;00m\n\u001B[1;32m   1174\u001B[0m \u001B[38;5;124;03m    Return the resulting stream.\u001B[39;00m\n\u001B[1;32m   1175\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1176\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbaseFilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/home/arthurb/Programmation/EduCDM/examples/DINA/Experiments/8-Preprocessing_pipeline/05-01-2024-11h21/running.log'"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.append('../')\n",
    "\n",
    "from Utility import DatasetProcessor\n",
    "xp_folder_name = \"8-Preprocessing_pipeline\"\n",
    "\n",
    "rel_data_path =\"../Data\"\n",
    "rel_xp_path = \"../Experiments\"\n",
    "abs_xp_path = \"/home/arthurb/Programmation/portrait/Experiments\"\n",
    "\n",
    "dataset_name = 'assist0910'\n",
    "exp = DatasetProcessor(xp_folder_name, data_path=rel_data_path, experiment_path=rel_xp_path)\n",
    "exp.process_from_file(dataset_name,abs_xp_path + \"/\" + xp_folder_name + \"/\" + \"prepro_\"+dataset_name + \".csv\")\n",
    "\n",
    "exp.DINA_transform(dataset_name=dataset_name, batch_size=32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T10:21:15.175057194Z",
     "start_time": "2024-01-05T10:21:12.822117671Z"
    }
   },
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training and Persistence"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 7534/7534 [00:54<00:00, 139.51it/s]\n",
      "evaluating: 100%|██████████| 1036/1036 [00:00<00:00, 1287.18it/s]\n",
      "Epoch 1: 100%|██████████| 7534/7534 [01:02<00:00, 120.28it/s]\n",
      "evaluating: 100%|██████████| 1036/1036 [00:00<00:00, 1318.61it/s]\n",
      "INFO:root:save parameters to dina.params\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] LogisticLoss: 0.705863\n",
      "[Epoch 0] auc: 0.508466, accuracy: 0.495035\n",
      "[Epoch 1] LogisticLoss: 0.702710\n",
      "[Epoch 1] auc: 0.517560, accuracy: 0.504724\n"
     ]
    }
   ],
   "source": [
    "from EduCDM import GDDINA\n",
    "\n",
    "cdm = GDDINA(4164, 17747, knowledge_num)\n",
    "\n",
    "cdm.train(train, valid, epoch=2)\n",
    "cdm.save(\"dina.params\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading and Testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:load parameters from dina.params\n",
      "evaluating: 100%|██████████| 2248/2248 [00:01<00:00, 1301.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc: 0.523625, accuracy: 0.509630\n"
     ]
    }
   ],
   "source": [
    "cdm.load(\"dina.params\")\n",
    "auc, accuracy = cdm.eval(test)\n",
    "print(\"auc: %.6f, accuracy: %.6f\" % (auc, accuracy))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
